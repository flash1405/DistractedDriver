{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackathonProject-DriverDistraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flash1405/DistractedDriver/blob/main/HackathonProject_DriverDistraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSVcJcxlKZ5v"
      },
      "source": [
        "#@title Run this to download data and prepare the environment! { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def label_to_numpy(labels):\n",
        "  final_labels = np.zeros((len(labels), 4))\n",
        "  for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    if label == 'Attentive':\n",
        "      final_labels[i,:] = np.array([1, 0, 0, 0])\n",
        "    if label == 'DrinkingCoffee':\n",
        "      final_labels[i,:] = np.array([0, 1, 0, 0])\n",
        "    if label == 'UsingMirror':\n",
        "      final_labels[i,:] = np.array([0, 0, 1, 0])\n",
        "    if label == 'UsingRadio':\n",
        "      final_labels[i,:] = np.array([0, 0, 0, 1])\n",
        "  return final_labels\n",
        "\n",
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "    \n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = shear)\n",
        "  return augment(data, fun)\n",
        "  \n",
        "def flip_left_right(data):\n",
        "  fun = augmenters.Fliplr()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data):\n",
        "  fun = augmenters.Flipud()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "  \n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of? \n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    metadata = metadata[keep_idx]\n",
        "    \n",
        "    # Get dataframes for each class.\n",
        "    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "\n",
        "    # Get number of items in class with lowest number of images.\n",
        "    num_samples_train = min(df_coffee_train.shape[0], \\\n",
        "                            df_mirror_train.shape[0], \\\n",
        "                            df_attentive_train.shape[0], \\\n",
        "                            df_radio_train.shape[0])\n",
        "    num_samples_test = min(df_coffee_test.shape[0], \\\n",
        "                            df_mirror_test.shape[0], \\\n",
        "                            df_attentive_test.shape[0], \\\n",
        "                            df_radio_test.shape[0])\n",
        "\n",
        "    # Resample each of the classes and concatenate the images.\n",
        "    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n",
        "                          df_mirror_train.sample(num_samples_train), \\\n",
        "                          df_attentive_train.sample(num_samples_train), \\\n",
        "                          df_radio_train.sample(num_samples_train) ])\n",
        "    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n",
        "                          df_mirror_test.sample(num_samples_test), \\\n",
        "                          df_attentive_test.sample(num_samples_test), \\\n",
        "                          df_radio_test.sample(num_samples_test) ])\n",
        "    \n",
        "    metadata = pd.concat( [metadata_train, metadata_test] )\n",
        "    \n",
        "    return metadata\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True \n",
        "    '''\n",
        "    # Get dataframes for each class.\n",
        "    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "\n",
        "    # Get number of items in class with lowest number of images.\n",
        "    num_samples_train = min(df_coffee_train.shape[0], \\\n",
        "                            df_mirror_train.shape[0], \\\n",
        "                            df_attentive_train.shape[0], \\\n",
        "                            df_radio_train.shape[0])\n",
        "    num_samples_test = min(df_coffee_test.shape[0], \\\n",
        "                            df_mirror_test.shape[0], \\\n",
        "                            df_attentive_test.shape[0], \\\n",
        "                            df_radio_test.shape[0])\n",
        "\n",
        "    # Resample each of the classes and concatenate the images.\n",
        "    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n",
        "                          df_mirror_train.sample(num_samples_train), \\\n",
        "                          df_attentive_train.sample(num_samples_train), \\\n",
        "                          df_radio_train.sample(num_samples_train) ])\n",
        "    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n",
        "                          df_mirror_test.sample(num_samples_test), \\\n",
        "                          df_attentive_test.sample(num_samples_test), \\\n",
        "                          df_radio_test.sample(num_samples_test) ])\n",
        "    \n",
        "    metadata = pd.concat( [metadata_train, metadata_test] )\n",
        "    \n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "  \n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    ### cv2.imshow('image', data)\n",
        "    \n",
        "    \n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels      \n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def get_misclassified_data(data, labels, predictions):\n",
        "    '''\n",
        "    Gets the data and labels that are misclassified in a classification task\n",
        "    Returns:\n",
        "    -missed_data\n",
        "    -missed_labels\n",
        "    -predicted_labels (corresponding to missed_labels)\n",
        "    -missed_index (indices of items in original dataset)\n",
        "    '''\n",
        "    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n",
        "    missed_labels    = labels[missed_index]\n",
        "    missed_data      = data[missed_index,:]\n",
        "    predicted_labels = predictions[missed_index]\n",
        "    return missed_data, missed_labels, predicted_labels, missed_index\n",
        "\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry. \n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'acc', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.25, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.01, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      if dropout:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def transferClassifier(num_hidden_layers, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten()) \n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(units = 64, activation = 'relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])    \n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = True):\n",
        "    expert_dict = {'VGG16': VGG16, \n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet', \n",
        "                                              include_top = False, \n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "      \n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'], \n",
        "                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications import VGG16, VGG19, ResNet50, DenseNet121\n",
        "\n",
        "from imgaug import augmenters \n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "image_data_url       = 'https://drive.google.com/uc?id=1qmTuUyn0525-612yS-wkp8gHB72Wv_XP'\n",
        "metadata_url         = 'https://drive.google.com/uc?id=1OfKnq3uIT29sXjWSZqOOpceig8Ul24OW'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 4\n",
        "nn_params['loss']              = 'categorical_crossentropy'\n",
        "nn_params['output_activation'] = 'softmax'\n",
        "\n",
        "###\n",
        "gdown.download(image_data_url, image_data_path , True)\n",
        "gdown.download(metadata_url, metadata_path , True)\n",
        "\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "model_to_string        = lambda model: helpers.model_to_string(model)\n",
        "get_misclassified_data = helpers.get_misclassified_data;\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRkJOP9xLUv1",
        "cellView": "form"
      },
      "source": [
        "#@title Split the data into train and test\n",
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()\n",
        "train_data = train_data.reshape([-1, 64, 64, 3])\n",
        "test_data = test_data.reshape([-1, 64, 64, 3])\n",
        "\n",
        "# Convert string labels into numpy arrays.\n",
        "train_labels = label_to_numpy(train_labels)\n",
        "test_labels = label_to_numpy(test_labels)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHB765SlHM3M",
        "cellView": "form"
      },
      "source": [
        "#@title Run to train model\n",
        "from google.colab import files\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "transfer = TransferClassifier(name = 'VGG16')\n",
        "vgg_expert = VGG16(weights = 'imagenet', include_top = False, input_shape = (64, 64, 3))\n",
        "vgg_model = Sequential()\n",
        "vgg_model.add(vgg_expert)\n",
        "vgg_model.add(GlobalAveragePooling2D())\n",
        "vgg_model.add(Dense(1024, activation = 'relu'))\n",
        "vgg_model.add(Dense(512, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(512, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(4, activation = 'softmax'))\n",
        "vgg_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "              metrics=['accuracy'])\n",
        "history = vgg_model.fit(train_data, train_labels, epochs = 4, validation_data = (train_data, train_labels), shuffle = True, callbacks = [monitor])\n",
        "#plot_acc(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDz2LtGgpQt4"
      },
      "source": [
        "Download images from this Google Drive link and upload them from your local machine in the next code block to check the model's functioning. Try not to use images from the internet since the image shape could be wrong and not give the right prediction, but it is very much possible it can work. The link for test images is - https://drive.google.com/drive/folders/1TJMulvrhM7A-w8HvthGzpW3_eQiQjQWT?usp=sharing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZNXUnDp083k",
        "cellView": "form"
      },
      "source": [
        "#@title Check Predictions - Try running again if it does not work the first time\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "image = load_img(fn, target_size=(64, 64))\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "image = img_to_array(image)\n",
        "image = image.reshape((-1, 64,64,3))\n",
        "#image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "image = preprocess_input(image)\n",
        "pred = vgg_model.predict_classes(image)\n",
        "p = []\n",
        "if(pred==0):\n",
        "  p.append('Not Distracted. Attentive')\n",
        "elif(pred==1):\n",
        "  p.append('Distracted. DrinkingCoffee')\n",
        "elif(pred==2):\n",
        "  p.append('Distracted. UsingMirror')\n",
        "elif(pred==3):\n",
        "  p.append('Distracted. UsingRadio')\n",
        "predictions = np.array(p)\n",
        "print(\"Label - \"+fn)\n",
        "print(\"Prediction - \"+str(predictions[0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}